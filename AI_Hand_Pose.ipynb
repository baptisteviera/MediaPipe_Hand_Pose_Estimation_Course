{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Install and import Dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "!pip install mediapipe opencv-python"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Draw Hands"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=https://google.github.io/mediapipe/images/mobile/hand_landmarks.png>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Confidence\n",
    "    # Detctioon :\n",
    "        # treshold for the initial detection to be succesful\n",
    "    # Tracking :\n",
    "        # treshold for tracking after detection\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # BGR to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal \n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        # no mirror effect !\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true in order to be able to draw on the image\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Detections\n",
    "        #print(results)\n",
    "        \n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks: # we check here whether or not we have results\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n",
    "                                         )\n",
    "            \n",
    "        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Be careful !\n",
    "If in our results.multi_hand_landmarks, we have only one \"none\" the return \"non\" !"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(results.multi_hand_landmarks)\n",
    "# Coordinates\n",
    " # X : Landmark position in the horizontal axis\n",
    " # Y : Landmark position in the vertical axis\n",
    " # Z : Landmark depth from the camera\n",
    "\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[landmark {\n",
      "  x: 0.09185916185379028\n",
      "  y: 0.8893988132476807\n",
      "  z: 5.6761047744657844e-05\n",
      "}\n",
      "landmark {\n",
      "  x: 0.19781965017318726\n",
      "  y: 0.9023101925849915\n",
      "  z: -0.04039996489882469\n",
      "}\n",
      "landmark {\n",
      "  x: 0.292509526014328\n",
      "  y: 0.8647773265838623\n",
      "  z: -0.05782293155789375\n",
      "}\n",
      "landmark {\n",
      "  x: 0.36464643478393555\n",
      "  y: 0.8346713781356812\n",
      "  z: -0.0781816691160202\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4311043620109558\n",
      "  y: 0.8459142446517944\n",
      "  z: -0.10424064844846725\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2618615925312042\n",
      "  y: 0.601689338684082\n",
      "  z: 0.028713099658489227\n",
      "}\n",
      "landmark {\n",
      "  x: 0.31063297390937805\n",
      "  y: 0.4776536524295807\n",
      "  z: 0.015686405822634697\n",
      "}\n",
      "landmark {\n",
      "  x: 0.33842170238494873\n",
      "  y: 0.3987528085708618\n",
      "  z: -0.006130164954811335\n",
      "}\n",
      "landmark {\n",
      "  x: 0.35615527629852295\n",
      "  y: 0.3290543854236603\n",
      "  z: -0.02629723958671093\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2059718668460846\n",
      "  y: 0.5563479661941528\n",
      "  z: 0.02009056694805622\n",
      "}\n",
      "landmark {\n",
      "  x: 0.24333056807518005\n",
      "  y: 0.40692418813705444\n",
      "  z: 0.019885044544935226\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2669984698295593\n",
      "  y: 0.31137195229530334\n",
      "  z: -0.004615313373506069\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2838769555091858\n",
      "  y: 0.23526161909103394\n",
      "  z: -0.020574945956468582\n",
      "}\n",
      "landmark {\n",
      "  x: 0.14784619212150574\n",
      "  y: 0.5403491854667664\n",
      "  z: -0.0027697694022208452\n",
      "}\n",
      "landmark {\n",
      "  x: 0.17295107245445251\n",
      "  y: 0.393924355506897\n",
      "  z: -0.011844002641737461\n",
      "}\n",
      "landmark {\n",
      "  x: 0.19587373733520508\n",
      "  y: 0.2991190254688263\n",
      "  z: -0.03525911644101143\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2143489271402359\n",
      "  y: 0.22414681315422058\n",
      "  z: -0.051132842898368835\n",
      "}\n",
      "landmark {\n",
      "  x: 0.0819532722234726\n",
      "  y: 0.5494368076324463\n",
      "  z: -0.033378470689058304\n",
      "}\n",
      "landmark {\n",
      "  x: 0.078327476978302\n",
      "  y: 0.419444739818573\n",
      "  z: -0.05251244083046913\n",
      "}\n",
      "landmark {\n",
      "  x: 0.08073882758617401\n",
      "  y: 0.3328167498111725\n",
      "  z: -0.07359232008457184\n",
      "}\n",
      "landmark {\n",
      "  x: 0.08466780185699463\n",
      "  y: 0.25335371494293213\n",
      "  z: -0.09135158360004425\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(list(enumerate(results.multi_hand_landmarks)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mp_hands.HAND_CONNECTIONS"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Output Images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.mkdir('Output images')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Confidence\n",
    "    # Detctioon :\n",
    "        # treshold for the initial detection to be succesful\n",
    "    # Tracking :\n",
    "        # treshold for tracking after detection\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # BGR to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal \n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        # no mirror effect !\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true in order to be able to draw on the image\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Detections\n",
    "        #print(results)\n",
    "        \n",
    "        # Rendering results\n",
    "        print(results.multi_hand_landmarks)\n",
    "        # we check here whether or not we have results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                    mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                    mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n",
    "                                         )\n",
    "            \n",
    "        \n",
    "        # Save our image\n",
    "        \n",
    "        #cv2.imwrite(os.path.join('Output images','{}.jpg'.format(uuid.uuid1())),image)\n",
    "\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "ls"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " AI_Hand_Pose.ipynb        MediaPipeHandPose-main.zip\n",
      " \u001b[0m\u001b[01;34mMediaPipeHandPose-main\u001b[0m/  \u001b[01;34m'Output images'\u001b[0m/\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(results.multi_hand_landmarks)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Detect Left and Right Hands"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "mp_hands.HandLandmark.WRIST"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<HandLandmark.WRIST: 0>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.PINKY_TIP]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "x: 0.08466780185699463\n",
       "y: 0.25335371494293213\n",
       "z: -0.09135158360004425"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results.multi_handedness.classification[0]\n",
    "# in order to have the lable name of the hand"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Function get_label arguments\n",
    "- index: the hand result i.e 0 or 1\n",
    "- hand: the actual hand landmarks\n",
    "- results: all detections from model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def get_label(index, hand, results):\n",
    "    output = None\n",
    "    for idx, classification in enumerate(results.multi_handedness):\n",
    "         if classification.classification[0].index == index:\n",
    "             # Process results\n",
    "             label = classification.classification[0].label\n",
    "             score = classification.classification[0].score\n",
    "             text = '{} {}'.format(label, round(score, 2))\n",
    "\n",
    "             # Extract Coordinates\n",
    "             \"\"\"\n",
    "             coords = tuple\n",
    "             (\n",
    "                np.multiply\n",
    "                (\n",
    "                    np.array\n",
    "                    (\n",
    "                            (\n",
    "                                hand.landmark[mp_hands.HandLandmark.WRIST].x,\n",
    "                                hand.landmark[mp_hands.HandLandmark.WRIST].y\n",
    "                            )\n",
    "                    ),\n",
    "                    [640,480]\n",
    "                )\n",
    "                .astype(int)\n",
    "            )\n",
    "            \"\"\"\n",
    "             coords = tuple(np.multiply(np.array((hand.landmark[mp_hands.HandLandmark.WRIST].x, hand.landmark[mp_hands.HandLandmark.WRIST].y)),[640,480]).astype(int))\n",
    "\n",
    "             output = text, coords\n",
    "\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "hand.landmark[mp_hands.HandLandmark.WRIST].x+5"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.939835727214813"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# in order to understand \n",
    "results.multi_handedness[0].classification[0].score"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-581648c46f48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# in order to understand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_handedness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#print(num)\n",
    "#print(hand)\n",
    "#print(results)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "get_label(num,hand,results)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-30b63f06731b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-e414c306f0f7>\u001b[0m in \u001b[0;36mget_label\u001b[0;34m(index, hand, results)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_handedness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m          \u001b[0;32mif\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0;31m# Process results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Confidence\n",
    "    # Detctioon :\n",
    "        # treshold for the initial detection to be succesful\n",
    "    # Tracking :\n",
    "        # treshold for tracking after detection\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # BGR to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal \n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        # no mirror effect !\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true in order to be able to draw on the image\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Detections\n",
    "        #print(results)\n",
    "        \n",
    "        # Rendering results\n",
    "        # print(results.multi_hand_landmarks)\n",
    "        # we check here whether or not we have results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                \n",
    "                # becareful doesn't work !\n",
    "                mp_drawing.draw_landmarks(image,hand, mp_hands.HAND_CONNECTIONS, mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),)\n",
    "            \n",
    "        \n",
    "                # Render left or right detection\n",
    "                if get_label(num, hand, results):\n",
    "                    text, coord = get_label(num, hand, results)\n",
    "                    cv2.putText(image, text, coord, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        # Save our image\n",
    "        \n",
    "        #cv2.imwrite(os.path.join('Output images','{}.jpg'.format(uuid.uuid1())),image)\n",
    "\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Calculate Multiple Angles"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "joint_list = [[8,7,6],[12,11,10],[1,2,3]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def draw_finger_angles(image, results, joint_list):\n",
    "    # Loop through hands\n",
    "    for hand in results.multi_hand_landmarks:\n",
    "        #Loop through joint sets\n",
    "        for joint in joint_list:\n",
    "            a = np.array([hand.landmark[joint[0]].x, hand.landmark[joint[0]].y]) # First\n",
    "            b = np.array([hand.landmark[joint[1]].x, hand.landmark[joint[1]].y]) # Mid\n",
    "            c = np.array([hand.landmark[joint[2]].x, hand.landmark[joint[2]].y]) # End\n",
    "            # a(x_a,y_a) et b(x_b,y_b)\n",
    "            # coord vect ba : (x_a - x_b, y_a - y_b)\n",
    "            # take the vector ba and not ab because angle in b\n",
    "            v_ba_x = a[0]-b[0]\n",
    "            v_ba_y = a[1]-b[1]\n",
    "            v_ba = np.array([v_ba_x,v_ba_y])\n",
    " \n",
    "            v_bc_x = c[0]-b[0]\n",
    "            v_bc_y = c[1]-b[1]\n",
    "            v_bc = np.array([v_bc_x,v_bc_y])\n",
    "\n",
    "            # angle = atan2(vector2.y, vector2.x) - atan2(vector1.y, vector1.x);\n",
    "            radians = np.arctan2(v_bc_y, v_bc_x) - np.arctan2(v_ba_y, v_ba_x)\n",
    "            #radian = np.arctan2(c[1]-b[1],c[0]-b[0]) - np.arctan2(a[1]-b[1],a[0]-b[0])\n",
    "            angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "            if angle > 180.0:\n",
    "                angle = 360 - angle\n",
    "\n",
    "            cv2.putText(image,str(round(angle,2)), tuple(np.multiply(b, [640, 480]).astype(int)),cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "    return image         "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Confidence\n",
    "    # Detctioon :\n",
    "        # treshold for the initial detection to be succesful\n",
    "    # Tracking :\n",
    "        # treshold for tracking after detection\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # BGR to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal \n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        # no mirror effect !\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true in order to be able to draw on the image\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Detections\n",
    "        #print(results)\n",
    "        \n",
    "        # Rendering results\n",
    "        #print(results.multi_hand_landmarks)\n",
    "        # we check here whether or not we have results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                \n",
    "                # becareful doesn't work !\n",
    "                mp_drawing.draw_landmarks(image,hand, mp_hands.HAND_CONNECTIONS, mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),)\n",
    "            \n",
    "        \n",
    "                # Render left or right detection\n",
    "                if get_label(num, hand, results):\n",
    "                    text, coord = get_label(num, hand, results)\n",
    "                    cv2.putText(image, text, coord, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "            # Draw angles to image from joint list\n",
    "            draw_finger_angles(image,results,joint_list)\n",
    "            \n",
    "                 \n",
    "\n",
    "\n",
    "        # Save our image\n",
    "        \n",
    "        #cv2.imwrite(os.path.join('Output images','{}.jpg'.format(uuid.uuid1())),image)\n",
    "\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('mediapipe_env': conda)"
  },
  "interpreter": {
   "hash": "9f66f92bafb2a87521898abadf1439f0b1bb8b49a280e87ba17f5a7d61d4c006"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}